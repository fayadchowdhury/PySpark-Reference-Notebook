{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a49e299",
   "metadata": {},
   "source": [
    "### Basic Spark imports to set up session\n",
    "\n",
    "The Spark session gives the entire application some context and helps the master node communicate with the worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a SparkSession object can perform the most common data processing tasks\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('PySpark Practice').getOrCreate() # will return existing session if one was created before and was not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get some info about the spark session that is currently running\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0197d",
   "metadata": {},
   "source": [
    "### Read dataset and define schemas\n",
    "\n",
    "Define dataset schemas for each of the 3 DAT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62da386",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"TwitterMoviesLatest-11OCT23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdata = dataset_folder+\"/users.dat\"\n",
    "ratingdata = dataset_folder+\"/ratings.dat\"\n",
    "moviedata = dataset_folder+\"/movies.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "# It is usually a good idea to define the schema for pyspark to read CSVs nicely\n",
    "# string -> StringType, int -> IntegerType\n",
    "# Be sure to import types from pyspark.sql\n",
    "userdata_schema = types.StructType([\n",
    "    types.StructField('serial', types.IntegerType()),\n",
    "    types.StructField('user_id', types.StringType()),\n",
    "])\n",
    "\n",
    "moviedata_schema = types.StructType([\n",
    "    types.StructField('movie_id', types.StringType()),\n",
    "    types.StructField('movie_title_year', types.StringType()),\n",
    "    types.StructField('movie_genre', types.StringType()),\n",
    "])\n",
    "\n",
    "ratingdata_schema = types.StructType([\n",
    "    types.StructField('user_id', types.StringType()),\n",
    "    types.StructField('movie_id', types.StringType()),\n",
    "    types.StructField('rating', types.IntegerType()),\n",
    "    types.StructField('timestamp', types.DoubleType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdata_df = spark.read.csv(userdata, sep=\"::\", schema=userdata_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2381f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df = spark.read.csv(moviedata, sep=\"::\", schema=moviedata_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingdata_df = spark.read.csv(ratingdata, sep=\"::\", schema=ratingdata_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check schema information\n",
    "userdata_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first n (5, in this case) rows of df\n",
    "userdata_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingdata_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e799fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingdata_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957215ff",
   "metadata": {},
   "source": [
    "### Transform datasets\n",
    "\n",
    "Some of the data is weirdly inserted in the columns (movie_title (year), genre|genre|genre, epoch timestamps etc.). Here we want to convert it into a flatter style. We also don't want to drop null values right away (maybe think of imputing the values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helps us split columns on patterns\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df.select([\"movie_title_year\", \"movie_genre\"]).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column on \"\\\\(\" (the \\\\ is needed to escape the character)\n",
    "split_movie_title_year = split(moviedata_df[\"movie_title_year\"], \" \\\\(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = split_movie_title_year.getItem(0) # Movie title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2243c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_intermediate = split_movie_title_year.getItem(1)\n",
    "year = split(year_intermediate, \"\\\\)\").getItem(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df2 = moviedata_df.withColumns({\n",
    "    \"movie_title\": title,\n",
    "    \"movie_year\": year\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c944cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df2.drop(\"movie_title_year\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df2 = moviedata_df2.withColumn(\"movie_genres\", split(moviedata_df2[\"movie_genre\"], \"\\\\|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e96ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df2.drop(\"movie_genre\").drop(\"movie_title_year\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df = moviedata_df2.select([\"movie_id\", \"movie_title\", \"movie_year\", \"movie_genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd370e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary dataframes and columns\n",
    "del moviedata_df2\n",
    "del split_movie_title_year\n",
    "del title\n",
    "del year_intermediate\n",
    "del year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cebd1b",
   "metadata": {},
   "source": [
    "### Merging the data\n",
    "\n",
    "Join rating data across users and movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0819dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = ratingdata_df.join(moviedata_df, [\"movie_id\"], \"inner\").join(userdata_df, [\"user_id\"], \"inner\")\n",
    "merged_df = merged_df.drop(merged_df[\"serial\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d74f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to proper timestamp\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "merged_df = merged_df.withColumn(\"timestamp_proper\", to_timestamp(merged_df[\"timestamp\"])).drop(merged_df[\"timestamp\"]).withColumnRenamed(\"timestamp_proper\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57209223",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "merged_df = merged_df.select([\"movie_title\", \"movie_year\", \"movie_genres\", \"user_id\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sort(merged_df[\"timestamp\"].desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd91a1",
   "metadata": {},
   "source": [
    "### Grouped stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5510a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of and min, max and avg ratings across movies\n",
    "from pyspark.sql.functions import sum, avg, max, min, mean, count\n",
    "\n",
    "movieratingstats_df = merged_df.groupBy(\"movie_title\").agg(\n",
    "    count(\"rating\").alias(\"num_ratings\"),\n",
    "    min(\"rating\").alias(\"min_rating\"),\n",
    "    max(\"rating\").alias(\"max_rating\"),\n",
    "    avg(\"rating\").alias(\"avg_rating\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieratingstats_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0649f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check across different time periods\n",
    "from pyspark.sql.functions import year\n",
    "movieratingyearstats_df = merged_df.withColumn(\"year\", year(\"timestamp\"))\n",
    "movieratingyearstats_df = movieratingyearstats_df.drop(movieratingyearstats_df[\"timestamp\"])\n",
    "movieratingyearstats_df = movieratingyearstats_df.sort(movieratingyearstats_df[\"year\"].desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4adb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieratingyearstats_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how movies performed in terms of ratings over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528df233",
   "metadata": {},
   "source": [
    "### User-movie stats\n",
    "\n",
    "This is a little harder to do given the price limits around the Twitter API. I can do 25 user profile requests every 24 hours, which is pathetic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with usernames and build user profiles based on what they rated\n",
    "userdata_df.select(\"user_id\").distinct().count() # 65771 unique user IDs\n",
    "userdata_df = userdata_df.dropDuplicates([\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if users' recommendations/tastes changed over time and how"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
